# -*- coding: utf-8 -*-
"""pima-indians-diabetes-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fpWUUxDeAu1atD0hOuJgYFJ-iYDiBqID

# Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from mlxtend.plotting import plot_decision_regions
import missingno as msno
from pandas.plotting import scatter_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

"""# Reading data from CSV file"""

diabetes_df = pd.read_csv('diabetes.csv')

diabetes_df.head()

"""# Exploratory Data Analysis (EDA)"""

diabetes_df.columns

diabetes_df.info()

diabetes_df.describe()

diabetes_df.describe().T

diabetes_df.isnull()

diabetes_df.isnull().sum()

diabetes_df_copy = diabetes_df.copy(deep= True)
diabetes_df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.nan)

print(diabetes_df_copy.isnull().sum())

"""# Data Visualization"""

# Plotting the data distribution plots

p = diabetes_df.hist(figsize = (20,20))

# AIming to impute NaN values for the columns in accordance with their distribution.

diabetes_df_copy['Glucose'].fillna(diabetes_df_copy['Glucose'].mean(), inplace = True)
diabetes_df_copy['BloodPressure'].fillna(diabetes_df_copy['BloodPressure'].mean(), inplace = True)
diabetes_df_copy['SkinThickness'].fillna(diabetes_df_copy['SkinThickness'].median(), inplace = True)
diabetes_df_copy['Insulin'].fillna(diabetes_df_copy['Insulin'].median(), inplace = True)
diabetes_df_copy['BMI'].fillna(diabetes_df_copy['BMI'].median(), inplace = True)

# Plotting the data distribution after removing NaN values.

p = diabetes_df_copy.hist(figsize = (20,20))

# Plotting null count analysis plot.

p = msno.bar(diabetes_df)

# Checking the balance of data by plotting the count of outcomes by their values.

color_wheel = {1 : '#00FF00', 2 : '#FF0000'}
bar_colors = diabetes_df['Outcome'].value_counts().index.map(lambda x: color_wheel.get(x + 1))
print(diabetes_df['Outcome'].value_counts())
p = diabetes_df['Outcome'].value_counts().plot(kind="bar", color=bar_colors)

p.set_title('Outcome Distribution')
p.set_xlabel('Outcome')
p.set_ylabel('Count')

# Plotting a Scatter Matrix of uncleaned data.

p = scatter_matrix(diabetes_df, figsize=(20,20))

# Plotting Pair PLot for cleaned data.

p = sns.pairplot(diabetes_df_copy, hue = 'Outcome')

"""# Correlation between all the features"""

# Correlation between all the features before cleaning data.

plt.figure(figsize = (12,10))
p = sns.heatmap(diabetes_df.corr(), annot = True, cmap = 'RdYlGn')

# Correlation between all the features after cleaning data.

plt.figure(figsize = (12,10))
p = sns.heatmap(diabetes_df_copy.corr(), annot = True, cmap = 'RdYlGn')

"""# Scaling the data"""

diabetes_df_copy.head()

sc_X = StandardScaler()
X = pd.DataFrame(sc_X.fit_transform(diabetes_df_copy.drop(['Outcome'], axis = 1)), columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'])
X.head()

y = diabetes_df_copy.Outcome

y

"""# Splitting data into Train and Test"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 42, stratify = y)

"""# Model Building

## K-Nearest Neighbour (KNN)
"""

train_scores = []
test_scores = []

for i in range (1, 15):
  knn = KNeighborsClassifier(i)
  knn.fit(X_train, y_train)

  train_scores.append(knn.score(X_train, y_train))
  test_scores.append(knn.score(X_test, y_test))

train_scores

test_scores

max_train_score = max(train_scores)

train_scores_index = [i for i, v in enumerate(train_scores) if v == max_train_score]
print('Maximum train score is {}% and k = {}.'.format(max_train_score*100, list(map(lambda x: x+1, train_scores_index))))

# Score that comes from testing on the data points that were split in the beginning to be used for testig solely.

max_train_score = max(test_scores)

train_scores_index = [i for i, v in enumerate(test_scores) if v == max_train_score]
print('Maximum test score is {}% and k = {}.'.format(max_train_score*100, list(map(lambda x: x+1, train_scores_index))))

plt.figure(figsize = (12,5))

p = sns.lineplot(x = range(1,15), y = train_scores, marker = '*', label = 'Train Score')
p = sns.lineplot(x = range(1,15), y = test_scores, marker = '*', label = 'Test Score')

"""The best result is captured at k = 11. Hence 11 is used for final model."""

knn = KNeighborsClassifier(11)
knn.fit(X_train, y_train)
knn.score(X_test, y_test)

# Plot the Decision Boundary

value = 20000
width = 20000
plot_decision_regions(X.values, y.values, clf = knn, legend = 2,
                      filler_feature_values = {2: value, 3: value, 4: value, 5: value, 6: value, 7: value},
                      filler_feature_ranges = {2: width, 3: width, 4: width, 5: width, 6: width, 7: width},
                      X_highlight = X_test.values)

plt.title('KNN with Diabetes Data')
plt.show()

"""## Confusion Matrix"""

y_prediction = knn.predict(X_test)

cnf_matrix = metrics.confusion_matrix(y_test, y_prediction)
p = sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu' , fmt = 'g')
plt.title('Confusion Matrix', y = 1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# Classification reports

print(classification_report(y_test, y_prediction))

"""## ROC-AUC Curve"""

y_prediction_proba = knn.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_prediction_proba)

plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr, label = 'KNN')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('KNN(n_neighbours=11) ROC Curve')
plt.show()

roc_auc_score(y_test, y_prediction_proba)

"""## Implementing GridSearchCV"""

## In case of Classifier like KNN the parameter to be tuned is n_neighbours.

param_grid = {'n_neighbors': np.arange(1, 50)}
knn = KNeighborsClassifier()
knn_cv = GridSearchCV(knn, param_grid, cv = 5)
knn_cv.fit(X, y)

print("Best Score: " + str(knn_cv.best_score_))
print("Best Parameters: " + str(knn_cv.best_params_))